{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzKHJ7fQgPKa011VJiUYlp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahmosthated/deep/blob/main/Untitled42.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IemCJOKQJ-2"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# Import Libraries\n",
        "# ----------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# ----------------------------\n",
        "# Load Dataset\n",
        "# ----------------------------\n",
        "# Toy housing dataset (1970s)\n",
        "data = pd.DataFrame({\n",
        "    \"sqft\": [1500, 1800, 2400, 3000, 3500],\n",
        "    \"price\": [7.2, 8.1, 10.5, 12.3, 13.5]  # in $1000s\n",
        "})\n",
        "\n",
        "X = data[[\"sqft\"]].values\n",
        "y = data[[\"price\"]].values\n",
        "\n",
        "# Train-test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling (important for neural networks)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "x_train = scaler_X.fit_transform(x_train)\n",
        "x_test = scaler_X.transform(x_test)\n",
        "y_train = scaler_y.fit_transform(y_train)\n",
        "y_test = scaler_y.transform(y_test)\n",
        "\n",
        "# ----------------------------\n",
        "# Build Neural Network Model\n",
        "# ----------------------------\n",
        "model = Sequential([\n",
        "    Dense(10, input_dim=1, activation=\"relu\"),\n",
        "    Dense(10, activation=\"relu\"),\n",
        "    Dense(1, activation=\"linear\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# ----------------------------\n",
        "# Train and Test the Model\n",
        "# (Train To Error Goal Template-2)\n",
        "# ----------------------------\n",
        "test_set = (x_test, y_test)\n",
        "\n",
        "# Early stopping: stop training when validation loss stops improving\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=200,                # maximum training cycles\n",
        "    validation_data=test_set,  # show test error during training\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# Make Predictions\n",
        "# ----------------------------\n",
        "pred_scaled = model.predict(x_test)\n",
        "pred = scaler_y.inverse_transform(pred_scaled)\n",
        "pred = pred[:, 0]\n",
        "y_test_flat = scaler_y.inverse_transform(y_test)[:, 0]\n",
        "\n",
        "print(\"Predicted values:\", pred)\n",
        "print(\"Actual values:\", y_test_flat)\n",
        "\n",
        "# ----------------------------\n",
        "# Plot Results\n",
        "# ----------------------------\n",
        "plt.scatter(x_test, y_test_flat, color=\"blue\", label=\"Actual\")\n",
        "plt.scatter(x_test, pred, color=\"red\", label=\"Predicted\")\n",
        "plt.xlabel(\"Square Footage (scaled)\")\n",
        "plt.ylabel(\"Price (in $1000s)\")\n",
        "plt.title(\"House Price Prediction (Neural Network with Early Stopping)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# Plot Training vs Validation Loss\n",
        "# ----------------------------\n",
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss (MSE)\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, you created a new copy of the notebook so the original remains intact. In the **Train and test the model** section, you updated the training process by adding epochs=10 inside model.fit(x_train, y_train, epochs=10). This made the model train for 10 cycles (epochs) instead of only one, which gave it more opportunities to learn from the data. As a result, you should have noticed that the **training loss (error)** dropped much more compared to before, meaning the model fit the training data better. Next, you wanted to measure not just training error but also **test error** (validation loss). To do this, you defined the test set with test_set = (x_test, y_test) and then added validation_data=test_set into your fit function, making it model.fit(x_train, y_train, epochs=10, validation_data=test_set). Now, when you ran the notebook, the training output displayed both **training loss** and **validation loss** after each epoch. This allowed you to see how well the model performed on unseen data while it trained. Finally, you replaced that training code with the **Train To Error Goal Template-2**, which is designed to keep training until the validation loss stops improving. This way, you don’t overfit to the training set — because even if training error keeps shrinking, we care more about minimizing validation error. When you ran the notebook, you probably saw that while training error continued to drop, validation error didn’t always go down — sometimes it even started to increase. That’s normal and is a sign of **overfitting**. The goal now is to re-run just the training cell a few times and watch the validation error. Sometimes it will fluctuate, but ideally, you want to see it get a little lower with more runs. The lowest validation error you achieve is the “sweet spot,” showing the best generalization to new data."
      ],
      "metadata": {
        "id": "PAonLw9cQUzb"
      }
    }
  ]
}